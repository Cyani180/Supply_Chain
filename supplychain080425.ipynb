{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49f160da-1bd7-493b-88ad-6592f33b7bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Company</th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating_number_customer</th>\n",
       "      <th>Heading</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Stars</th>\n",
       "      <th>Invitation</th>\n",
       "      <th>Dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>skatedeluxe</td>\n",
       "      <td>Sandra</td>\n",
       "      <td>2</td>\n",
       "      <td>Jederzeit wieder</td>\n",
       "      <td>&lt;p class=\"typography_body-l__v5JLj typography_...</td>\n",
       "      <td>5</td>\n",
       "      <td>Auf Einladung</td>\n",
       "      <td>5. M√§rz 2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>skatedeluxe</td>\n",
       "      <td>customer</td>\n",
       "      <td>2</td>\n",
       "      <td>Schnelle Lieferung</td>\n",
       "      <td>No comment</td>\n",
       "      <td>5</td>\n",
       "      <td>Auf Einladung</td>\n",
       "      <td>5. M√§rz 2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>skatedeluxe</td>\n",
       "      <td>Dexter</td>\n",
       "      <td>1</td>\n",
       "      <td>Bester Service und top Qualit√§t</td>\n",
       "      <td>&lt;p class=\"typography_body-l__v5JLj typography_...</td>\n",
       "      <td>5</td>\n",
       "      <td>Auf Einladung</td>\n",
       "      <td>4. M√§rz 2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>skatedeluxe</td>\n",
       "      <td>Stephan Lameck</td>\n",
       "      <td>1</td>\n",
       "      <td>Schnelligkeit</td>\n",
       "      <td>&lt;p class=\"typography_body-l__v5JLj typography_...</td>\n",
       "      <td>5</td>\n",
       "      <td>Auf Einladung</td>\n",
       "      <td>4. M√§rz 2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>skatedeluxe</td>\n",
       "      <td>Fritz Brack</td>\n",
       "      <td>2</td>\n",
       "      <td>Super Service</td>\n",
       "      <td>&lt;p class=\"typography_body-l__v5JLj typography_...</td>\n",
       "      <td>5</td>\n",
       "      <td>Auf Einladung</td>\n",
       "      <td>3. M√§rz 2025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      Company            Name  Rating_number_customer  \\\n",
       "0           0  skatedeluxe          Sandra                       2   \n",
       "1           1  skatedeluxe        customer                       2   \n",
       "2           2  skatedeluxe          Dexter                       1   \n",
       "3           3  skatedeluxe  Stephan Lameck                       1   \n",
       "4           4  skatedeluxe     Fritz Brack                       2   \n",
       "\n",
       "                           Heading  \\\n",
       "0                 Jederzeit wieder   \n",
       "1               Schnelle Lieferung   \n",
       "2  Bester Service und top Qualit√§t   \n",
       "3                    Schnelligkeit   \n",
       "4                    Super Service   \n",
       "\n",
       "                                             Comment  Stars     Invitation  \\\n",
       "0  <p class=\"typography_body-l__v5JLj typography_...      5  Auf Einladung   \n",
       "1                                         No comment      5  Auf Einladung   \n",
       "2  <p class=\"typography_body-l__v5JLj typography_...      5  Auf Einladung   \n",
       "3  <p class=\"typography_body-l__v5JLj typography_...      5  Auf Einladung   \n",
       "4  <p class=\"typography_body-l__v5JLj typography_...      5  Auf Einladung   \n",
       "\n",
       "          Dates  \n",
       "0  5. M√§rz 2025  \n",
       "1  5. M√§rz 2025  \n",
       "2  4. M√§rz 2025  \n",
       "3  4. M√§rz 2025  \n",
       "4  3. M√§rz 2025  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Integrate and view the datset supply chain and remove the columns that are not required\n",
    "\n",
    "df = pd.read_csv(\"supply_chain_project_trustpilot_advanced_merge.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7643fc4f-4d8a-4b54-a10b-c0408e9961ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Rating_number_customer</th>\n",
       "      <th>Stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18378.000000</td>\n",
       "      <td>18378.000000</td>\n",
       "      <td>18378.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9188.500000</td>\n",
       "      <td>3.602079</td>\n",
       "      <td>3.611927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5305.415959</td>\n",
       "      <td>6.258368</td>\n",
       "      <td>1.768108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4594.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9188.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13782.750000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>18377.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  Rating_number_customer         Stars\n",
       "count  18378.000000            18378.000000  18378.000000\n",
       "mean    9188.500000                3.602079      3.611927\n",
       "std     5305.415959                6.258368      1.768108\n",
       "min        0.000000                1.000000      1.000000\n",
       "25%     4594.250000                1.000000      1.000000\n",
       "50%     9188.500000                2.000000      5.000000\n",
       "75%    13782.750000                4.000000      5.000000\n",
       "max    18377.000000              263.000000      5.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18378 entries, 0 to 18377\n",
      "Data columns (total 9 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   Unnamed: 0              18378 non-null  int64 \n",
      " 1   Company                 18378 non-null  object\n",
      " 2   Name                    18375 non-null  object\n",
      " 3   Rating_number_customer  18378 non-null  int64 \n",
      " 4   Heading                 18378 non-null  object\n",
      " 5   Comment                 18378 non-null  object\n",
      " 6   Stars                   18378 non-null  int64 \n",
      " 7   Invitation              18378 non-null  object\n",
      " 8   Dates                   18378 non-null  object\n",
      "dtypes: int64(3), object(6)\n",
      "memory usage: 1.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.describe())\n",
    "display(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a57be969-f7b7-4745-b2b5-b668b4e7dfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"typography_body-l__v5JLj typography_appearance-default__t8iAq\" data-service-review-text-typography=\"true\">Sehr schnelle Lieferung, gutes Preis-Leistungsverh√§ltnis.</p>\n",
      "--------------------------------------------------------------------------------\n",
      "No comment\n",
      "--------------------------------------------------------------------------------\n",
      "<p class=\"typography_body-l__v5JLj typography_appearance-default__t8iAq\" data-service-review-text-typography=\"true\">Der bestellvorgang war unkompliziert, <br/>Die gew√ºnschten Produkte kamen schnell und entsprechen der zu erwartenden Qualit√§t,<br/> Immer wieder gern üëç‚úåÔ∏è</p>\n",
      "--------------------------------------------------------------------------------\n",
      "<p class=\"typography_body-l__v5JLj typography_appearance-default__t8iAq\" data-service-review-text-typography=\"true\">Ausgefallene Produkte</p>\n",
      "--------------------------------------------------------------------------------\n",
      "<p class=\"typography_body-l__v5JLj typography_appearance-default__t8iAq\" data-service-review-text-typography=\"true\">Super Service, extrem schnelle Lieferung, Top Qualit√§t zu super Preisen</p>\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Print the first 5 comments in full\n",
    "for comment in df['Comment'].head(5):\n",
    "    print(comment)\n",
    "    print('-' * 80)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a12b1746-36e3-4355-a4b7-60b2114c10cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sehr schnelle Lieferung, gutes Preis-Leistungsverh√§ltnis.\n",
      "--------------------------------------------------------------------------------\n",
      "No comment\n",
      "--------------------------------------------------------------------------------\n",
      "Der bestellvorgang war unkompliziert, \n",
      "--------------------------------------------------------------------------------\n",
      "Ausgefallene Produkte\n",
      "--------------------------------------------------------------------------------\n",
      "Super Service, extrem schnelle Lieferung, Top Qualit√§t zu super Preisen\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define a function to clean each comment\n",
    "def extract_comment(text):\n",
    "    if isinstance(text, str):\n",
    "        # Find text between the first \">\" and the next \"<\"\n",
    "        matches = re.findall(r'>([^<]+)<', text)\n",
    "        if matches:\n",
    "            return matches[0]\n",
    "    return text  # If not a string or no match, return as is\n",
    "\n",
    "# Apply the cleaning function to the Comment column\n",
    "df['Comment'] = df['Comment'].apply(extract_comment)\n",
    "\n",
    "# Now check the first 5 cleaned comments\n",
    "for comment in df['Comment'].head(5):\n",
    "    print(comment)\n",
    "    print('-' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70ca0e34-9bc4-46bb-b0b5-8d8e900c3df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jederzeit wieder Sehr schnelle Lieferung, gute...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Schnelle Lieferung No comment</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bester Service und top Qualit√§t Der bestellvor...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Schnelligkeit Ausgefallene Produkte</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Super Service Super Service, extrem schnelle L...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Stars\n",
       "0  Jederzeit wieder Sehr schnelle Lieferung, gute...      5\n",
       "1                      Schnelle Lieferung No comment      5\n",
       "2  Bester Service und top Qualit√§t Der bestellvor...      5\n",
       "3                Schnelligkeit Ausgefallene Produkte      5\n",
       "4  Super Service Super Service, extrem schnelle L...      5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Merge 'Heading' and 'Comment' into a new column called 'Text'\n",
    "df['Text'] = (df['Heading'].fillna('') + ' ' + df['Comment'].fillna('')).str.strip()\n",
    "\n",
    "# 2. Drop all columns except 'Text' and 'Stars'\n",
    "df = df[['Text', 'Stars']]\n",
    "\n",
    "# 3. Display the first few rows to check\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cae2511-0b28-435f-9275-cd5b7b12c62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A plot to better see the weighting of the individual values.\n",
    "\n",
    "sns.countplot(x=df['Stars'], hue=df['Stars'])\n",
    "plt.title('The Reviews')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e436dc7-691d-4616-ad88-643b02b0b46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stars\n",
       "5    10523\n",
       "1     5086\n",
       "4     1134\n",
       "3      873\n",
       "2      762\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Stars'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7050b804-4f7d-48e7-99c9-d740c2a0bc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rows 2, 3, 4 in the Stars column are deleted for better training and your better evaluation. Or not?\n",
    "# this will be addressed later in the workflow by using oversampling\n",
    "# oversampling can only be done on the train, i.e. after the train test split, to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4e77269-8223-4152-aa96-6a384d213df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Jederzeit wieder Sehr schnelle Lieferung, gute...\n",
       "1                         Schnelle Lieferung No comment\n",
       "2     Bester Service und top Qualit√§t Der bestellvor...\n",
       "3                   Schnelligkeit Ausgefallene Produkte\n",
       "4     Super Service Super Service, extrem schnelle L...\n",
       "5     Lieferung super schnell und Retoure war‚Ä¶ Liefe...\n",
       "6     Die Ware hat eine sehr hohe Qualit√§t ! Die War...\n",
       "7     zuverl√§ssig zuverl√§ssig, superschneller Versan...\n",
       "8     Stets gute Preise und tolle Aktionen Stets gut...\n",
       "9     Super Schnelle Lieferung und guter‚Ä¶ Super Schn...\n",
       "10    Gute Ware zu gutem Preis! Gute Ware zu gutem P...\n",
       "11    Schnelle Lieferung Schnelle Lieferung, tolles ...\n",
       "12    Nach anf√§nglichen lieferproblemen hat‚Ä¶ Nach an...\n",
       "13    Alles tutti Von der Bestellung bis zur Lieferu...\n",
       "14    Lieferung,Qualit√§t und Verpackung Top! Lieferu...\n",
       "15    Schneller Versand und top Ware Alles bestens w...\n",
       "16    Sehr wackelig aber nach dem Fest ziehen‚Ä¶ Sehr ...\n",
       "17    Super schnelle Lieferung Super schnelle Liefer...\n",
       "18                            Alles bestens! No comment\n",
       "19    Schnelle Lieferung Schnelle Lieferung, sehr ko...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The next step is to remove regular expressions and pop words that are not relevant.\n",
    "# Output some sentences\n",
    "df['Text'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57dd21c0-6184-41a2-b84f-7675d83f7a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are exclamation marks, but there are no more special characters.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are exclamation marks, but there are no more special characters.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1123f425-b819-461b-9fa6-5778293529ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3943/4169933976.py:10: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  return BeautifulSoup(text, \"html.parser\").get_text()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     jederzeit wieder sehr schnelle lieferung, gute...\n",
       "1                         schnelle lieferung no comment\n",
       "2     bester service und top qualit√§t der bestellvor...\n",
       "3                   schnelligkeit ausgefallene produkte\n",
       "4     super service super service, extrem schnelle l...\n",
       "5     lieferung super schnell und retoure war‚Ä¶ liefe...\n",
       "6     die ware hat eine sehr hohe qualit√§t ! die war...\n",
       "7     zuverl√§ssig zuverl√§ssig, superschneller versan...\n",
       "8     stets gute preise und tolle aktionen stets gut...\n",
       "9     super schnelle lieferung und guter‚Ä¶ super schn...\n",
       "10    gute ware zu gutem preis! gute ware zu gutem p...\n",
       "11    schnelle lieferung schnelle lieferung, tolles ...\n",
       "12    nach anf√§nglichen lieferproblemen hat‚Ä¶ nach an...\n",
       "13    alles tutti von der bestellung bis zur lieferu...\n",
       "14    lieferung,qualit√§t und verpackung top! lieferu...\n",
       "15    schneller versand und top ware alles bestens w...\n",
       "16    sehr wackelig aber nach dem fest ziehen‚Ä¶ sehr ...\n",
       "17    super schnelle lieferung super schnelle liefer...\n",
       "18                            alles bestens! no comment\n",
       "19    schnelle lieferung schnelle lieferung, sehr ko...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We put the text in lower case\n",
    "df[\"Text\"] = df[\"Text\"].str.lower()\n",
    "\n",
    "# the Text column is incorrectly formatted\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define a function to clean HTML\n",
    "def clean_html(text):\n",
    "    if isinstance(text, str):\n",
    "        return BeautifulSoup(text, \"html.parser\").get_text()\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "# Apply it to your 'Text' column\n",
    "df['Text'] = df['Text'].apply(clean_html)\n",
    "\n",
    "# check if it worked\n",
    "df[\"Text\"].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98187a0c-4fad-478d-82a8-e61f711ac75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[jederzeit, wieder, sehr, schnelle, lieferung,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[schnelle, lieferung, no, comment]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[bester, service, und, top, qualit√§t, der, bes...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[schnelligkeit, ausgefallene, produkte]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[super, service, super, service, ,, extrem, sc...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Stars\n",
       "0  [jederzeit, wieder, sehr, schnelle, lieferung,...      5\n",
       "1                 [schnelle, lieferung, no, comment]      5\n",
       "2  [bester, service, und, top, qualit√§t, der, bes...      5\n",
       "3            [schnelligkeit, ausgefallene, produkte]      5\n",
       "4  [super, service, super, service, ,, extrem, sc...      5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace missing values\n",
    "df['Text'] = df['Text'].fillna('')\n",
    "df['Text'] = df['Text'].astype(str)\n",
    "# tokenize\n",
    "df[\"Text\"] = df[\"Text\"].apply(word_tokenize)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fed4617-2edd-4ccb-a7d9-07df6205acde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'anderes', 'jetzt', 'jedes', 'ihrem', 'k√∂nnen', 'ihres', 'wirst', 'eines', 'jeden', 'eine', 'aller', 'uns', 'nur', 'der', 'da', 'das', 'von', 'ihr', 'welchen', 'da√ü', 'muss', 'solches', 'man', 'dein', 'meine', 'am', 'ich', 'dem', 'dieser', 'musste', 'welcher', 'wo', 'deines', 'einem', 'dieselbe', 'manche', 'den', 'seinem', 'seiner', 'hat', 'keines', 'deine', 'solche', 'andere', 'jenen', 'jenes', 'w√ºrden', 'wollte', 'unser', 'aus', 'vor', 'k√∂nnte', 'durch', 'wenn', 'weg', 'diesen', 'denselben', 'desselben', 'euer', 'keinen', 'wir', 'dir', 'jenem', 'jener', 'und', 'ihn', 'nichts', 'anders', 'einig', 'ihren', 'anderen', 'mich', 'weil', 'warst', 'seine', 'waren', 'zwar', 'als', 'anderm', 'dazu', 'er', 'ein', 'vom', 'solchem', 'indem', 'bin', 'anderer', 'also', 'die', 'dieses', 'einiger', 'zu', 'es', 'ist', 'um', 'dies', 'keine', 'viel', 'hinter', 'machen', 'war', 'bis', 'wird', 'eurem', 'derselben', 'alle', 'werde', 'meinem', 'nach', 'keinem', 'unsere', 'dasselbe', 'kein', 'seinen', 'gewesen', 'hatten', 'sondern', 'manchem', 'seines', 'ihre', 'einen', 'oder', 'dort', 'weiter', 'euren', 'einmal', 'haben', 'kann', 'ohne', 'manches', 'alles', 'hier', 'einige', 'sind', 'solchen', 'sein', 'doch', 'wieder', 'zum', 'bist', 'w√ºrde', 'bei', 'dich', 'jedem', 'jene', 'sollte', 'einiges', 'aber', 'sehr', 'unserem', 'etwas', 'eures', 'allen', 'ander', 'noch', 'euch', 'eurer', 'wollen', 'damit', 'gegen', 'demselben', 'andern', 'deiner', 'zwischen', 'dass', '√ºber', 'mein', 'soll', 'einer', 'einigen', 'jede', 'einigem', 'dessen', 'habe', 'denn', 'mir', 'selbst', 'an', 'dieselben', 'manchen', 'ihnen', 'will', 'ihrer', 'auch', 'sonst', 'allem', 'hin', 'unseren', 'mit', 'ob', 'so', 'keiner', 'was', 'hab', 'meiner', 'derer', 'eure', 'f√ºr', 'nun', 'wie', 'zur', 'derselbe', 'hatte', 'mancher', 'sie', 'in', 'meines', 'dann', 'des', 'welchem', 'meinen', 'diesem', 'auf', 'ins', 'w√§hrend', 'diese', 'deinem', 'ihm', 'unseres', 'unter', 'welche', 'welches', 'jeder', 'nicht', 'werden', 'solcher', 'anderr', 'du', 'deinen', 'sich', 'anderem', 'im'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty words variable\n",
    "# The applying from stopwrods filter on the text corpus.\n",
    "# correct in german !!!\n",
    "stop_words = set(stopwords.words('german'))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8c10784-4fa9-470b-9ef4-cc5b0f0ac46b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [jederzeit, schnelle, lieferung, gutes, preis-...\n",
       "1                    [schnelle, lieferung, no, comment]\n",
       "2     [bester, service, top, qualit√§t, bestellvorgan...\n",
       "3               [schnelligkeit, ausgefallene, produkte]\n",
       "4     [super, service, super, service, extrem, schne...\n",
       "5     [lieferung, super, schnell, retoure, war‚Ä¶, lie...\n",
       "6          [ware, hohe, qualit√§t, ware, hohe, qualit√§t]\n",
       "7     [zuverl√§ssig, zuverl√§ssig, superschneller, ver...\n",
       "8     [stets, gute, preise, tolle, aktionen, stets, ...\n",
       "9     [super, schnelle, lieferung, guter‚Ä¶, super, sc...\n",
       "10    [gute, ware, gutem, preis, gute, ware, gutem, ...\n",
       "11    [schnelle, lieferung, schnelle, lieferung, tol...\n",
       "12    [anf√§nglichen, lieferproblemen, hat‚Ä¶, anf√§ngli...\n",
       "13    [tutti, bestellung, lieferung, lief, perfekt, ...\n",
       "14    [lieferung, qualit√§t, verpackung, top, lieferu...\n",
       "15      [schneller, versand, top, ware, bestens, immer]\n",
       "16    [wackelig, fest, ziehen‚Ä¶, wackelig, fest, zieh...\n",
       "17    [super, schnelle, lieferung, super, schnelle, ...\n",
       "18                               [bestens, no, comment]\n",
       "19    [schnelle, lieferung, schnelle, lieferung, kom...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add to the list of stopwords the syntax elements we have identified that are not useful for text analysis\n",
    "# The special characters, punctuation will add to the stop_words set.\n",
    "# Define the stop_words_filtering function\n",
    "\n",
    "new_stop_words = [\",\", \".\", \"``\", \"@\", \"*\", \"(\", \")\", \"¬ß\", \"$\", \"&\", \"‚Ç¨\", \"...\", \"!\", \"?\", \"-\", \"_\", \">\", \"<\", \":\", \"/\", \"=\", \"--\", \"¬©\", \"~\", \";\", \"\\\\\", \"\\\\\\\\\"]\n",
    " \n",
    "stop_words.update(new_stop_words)\n",
    "\n",
    "def stop_words_filtering(words) : \n",
    "    tokens = []\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            tokens.append(word)\n",
    "    return tokens\n",
    "\n",
    "df[\"Text\"] = df[\"Text\"].apply(stop_words_filtering)\n",
    "df['Text'].head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b07e4f9a-2f8c-4d96-b00e-3282ed3f9560",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/f7984027-8341-4813-a985-\n",
      "[nltk_data]     c30afa0dff71/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/f7984027-8341-4813-a985-\n",
      "[nltk_data]     c30afa0dff71/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     ['[',``'``,'j',``'``,',',``'``,'e',``'``,',',`...\n",
       "1     ['[',``'``,'s',``'``,',',``'``,'c',``'``,',',`...\n",
       "2     ['[',``'``,'b',``'``,',',``'``,'e',``'``,',',`...\n",
       "3     ['[',``'``,'s',``'``,',',``'``,'c',``'``,',',`...\n",
       "4     ['[',``'``,'s',``'``,',',``'``,'u',``'``,',',`...\n",
       "5     ['[',``'``,'l',``'``,',',``'``,'i',``'``,',',`...\n",
       "6     ['[',``'``,'w',``'``,',',``'``,'a',``'``,',',`...\n",
       "7     ['[',``'``,'z',``'``,',',``'``,'u',``'``,',',`...\n",
       "8     ['[',``'``,'s',``'``,',',``'``,'t',``'``,',',`...\n",
       "9     ['[',``'``,'s',``'``,',',``'``,'u',``'``,',',`...\n",
       "10    ['[',``'``,'g',``'``,',',``'``,'u',``'``,',',`...\n",
       "11    ['[',``'``,'s',``'``,',',``'``,'c',``'``,',',`...\n",
       "12    ['[',``'``,'a',``'``,',',``'``,'n',``'``,',',`...\n",
       "13    ['[',``'``,'t',``'``,',',``'``,'u',``'``,',',`...\n",
       "14    ['[',``'``,'l',``'``,',',``'``,'i',``'``,',',`...\n",
       "15    ['[',``'``,'s',``'``,',',``'``,'c',``'``,',',`...\n",
       "16    ['[',``'``,'w',``'``,',',``'``,'a',``'``,',',`...\n",
       "17    ['[',``'``,'s',``'``,',',``'``,'u',``'``,',',`...\n",
       "18    ['[',``'``,'b',``'``,',',``'``,'e',``'``,',',`...\n",
       "19    ['[',``'``,'s',``'``,',',``'``,'c',``'``,',',`...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# The following block is used to ensure stopwords are filtered\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Make sure it's a string\n",
    "df['Text'] = df['Text'].astype(str)\n",
    "\n",
    "# Tokenize the sentences\n",
    "df['Text'] = df['Text'].apply(word_tokenize)\n",
    "\n",
    "# Remove stopwords (German stopwords)\n",
    "stop_words = set(stopwords.words('german'))\n",
    "\n",
    "def stop_words_filtering(words):\n",
    "    tokens = []\n",
    "    for word in words:\n",
    "        if word.lower() not in stop_words:\n",
    "            tokens.append(word)\n",
    "    return tokens\n",
    "\n",
    "df['Text'] = df['Text'].apply(stop_words_filtering)\n",
    "\n",
    "# Join the tokens back to strings and view the result\n",
    "df['Text'] = df['Text'].apply(lambda x: ''.join(x))\n",
    "df['Text'].head(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60a333f-d6ab-4d87-b0bf-b5e2a287a399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1500c9-af34-4e34-8434-2199ccbf8bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex for all points.\n",
    "# Regex for all figures and numbers.\n",
    "# Check that all the elements you wanted to remove have been removed from the dataframe\n",
    "\n",
    "for i in range (0, len(df['Text'])):\n",
    "    df.loc[i, 'Text'] = re.sub(r\"\\.+\", '', df.loc[i, 'Text'])\n",
    "\n",
    "#Regex for all figures and numbers\n",
    "for i in range (0, len(df['Text'])):\n",
    "    df.loc[i, 'Text'] = re.sub(r\"[0-9]+\", '', df.loc[i, 'Text'])\n",
    "\n",
    "#Check that all the elements you wanted to remove have been removed from the dataframe\n",
    "filtered = [i for i in df['Text']]\n",
    "print(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4a3ca7-7bd2-4ffc-94fb-028d747ef86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The text has been improved and unnecessary and disturbing elements have been removed. Various methods are now applied to the data.\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b092204-b31c-449e-9e60-61e8ce54e3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the explanatory variable from the variable to be predicted\n",
    "# It is necessary to systematically divide the data into a training and test set.\n",
    "\n",
    "X, y = df.Text, df.Stars\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.2, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eedb0fb-80b4-4cca-bdfb-e65b357f868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e4da41-a90b-4894-8cc3-a8d43c4964ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i attempted to use SMOTE but kept getting error after error, and eventually realised that i do not have permission to use SMOTE, even after trying to install it on Anaconda\n",
    "# if anyone else knows a trick to access SMOTE then please help\n",
    "# my method below is basic - it only copies existing 2 3 and 4 star reviews rather than synthetically creating new ones\n",
    "train_data = pd.DataFrame({'Text': X_train, 'Stars': y_train})\n",
    "# strip train data\n",
    "train_data['Text'] = train_data['Text'].astype(str).str.strip()\n",
    "\n",
    "# Basic Random Oversampling (manual)\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Combine your training features and labels temporarily\n",
    "train_data = pd.DataFrame({'Text': X_train, 'Stars': y_train})\n",
    "\n",
    "# Check original class distribution\n",
    "print(\"Original class distribution:\")\n",
    "print(train_data['Stars'].value_counts())\n",
    "\n",
    "# Find the maximum class count\n",
    "max_count = train_data['Stars'].value_counts().max()\n",
    "\n",
    "# Create a new oversampled dataframe\n",
    "oversampled_train_data = train_data.groupby('Stars').apply(lambda x: x.sample(max_count, replace=True, random_state=42)).reset_index(drop=True)\n",
    "\n",
    "# Check new class distribution\n",
    "print(\"\\nNew (oversampled) class distribution:\")\n",
    "print(oversampled_train_data['Stars'].value_counts())\n",
    "\n",
    "# Split it back into X and y\n",
    "X_train = oversampled_train_data['Text']\n",
    "y_train = oversampled_train_data['Stars']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726fb3f0-be40-4c44-a5f9-034f5f893a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the balance data stars 1,2,3,4,5 - balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2f5f3c-b4d5-46cd-8ffb-29315fd63b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Count Vectorize class is used here. It initialize a vectorizer.\n",
    "\n",
    "X_train = oversampled_train_data['Text']\n",
    "y_train = oversampled_train_data['Stars']\n",
    "\n",
    "# Clean up any missing or bad data\n",
    "X_train = X_train.dropna()\n",
    "X_train = X_train[X_train.str.strip().astype(bool)]  # remove empty strings\n",
    "\n",
    "# Make sure it's all strings\n",
    "X_train = X_train.astype(str)\n",
    "\n",
    "# Vectorize using count vectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "print(type(X_test))\n",
    "print(X_test.head())\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Convert X_test into a Series\n",
    "X_test = pd.Series(X_test)\n",
    "X_test = X_test.apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
    "# Now transform X_test\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac9a0c8-f99c-4be1-a365-94d2d9d1d4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemming or lamminization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df4eb61-76cd-4fdf-ac5f-e992ef213d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The datase is train the classification model. Therefore is the choose the Gradient Boosting algorithm.\n",
    "# value errors were occurring, 42109 and 42115 did not quite match - attempt to fix this problem\n",
    "# Create a new dataframe\n",
    "temp = pd.DataFrame({'Text': X_train, 'Stars': y_train})\n",
    "\n",
    "# Drop rows where Text or Stars are missing\n",
    "temp = temp.dropna()\n",
    "\n",
    "# Now reassign\n",
    "X_train = temp['Text']\n",
    "y_train = temp['Stars']\n",
    "\n",
    "# Re-vectorize\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "clf = GradientBoostingClassifier(\n",
    "        n_estimators = 100,\n",
    "        learning_rate = 1.0,\n",
    "        max_depth = 1,\n",
    "        random_state = 0\n",
    ")\n",
    "\n",
    "clf.fit(X_train_vec,y_train) # vectorisation was not previously referred here hence the errors\n",
    "\n",
    "y_pred = clf.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237aabd4-b7c2-494c-b730-ac5a8e731218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is calculated F-measure of the classification model.\n",
    "print( classification_report(y_test, y_pred))\n",
    "\n",
    "confusion_matrix = pd.crosstab(y_test,y_pred, rownames=['Actual class'], colnames=['Predicted class'])\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d78282-8d22-4f04-a2c6-13099d559fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\")\n",
    "print(r\"\"\"In the star's lines in the precision, recall and f1-score areas, improvements can be seen in the first and fifth lines, \n",
    "but deterioration can be seen in the scores in between.\n",
    "\n",
    "The macro avg and weighted avg have deteriorated in precision, \n",
    "which means that the ability to avoid false positives has decreased.\n",
    "\n",
    "The macro avg and weighted avg has become slightly better in recall and f1-score, \n",
    "which means the ability to correctly identify positive instances has increased and a balance between precision and recall has improved. \n",
    "Whereby the precision avoids false positives.\n",
    "\n",
    "In the Confution Matrix you can see that the FP and FN have decreased and the TN and TP have increased, \n",
    "which is very good, meaning that we can assume that more correct and false good or negative statements have been recognised.\"\"\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8432ba2e-dd71-4148-98e4-e3f5960244a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New comments are added to test the model.\n",
    "\n",
    "comments = [\"I am happy.\", \n",
    "            \"I am disappointed.\", \n",
    "            \"Why can't it always be like this.\",\n",
    "            \"Never again.\",\n",
    "            \"I didn't like the product.\",\n",
    "            \"I would have liked more help.\", \n",
    "            \"It all took too long.\", \n",
    "            \"I was very disappointed.\",\n",
    "            \"Any time again.\",\n",
    "            \"The service was not good.\",\n",
    "            \"Everything was great\",\n",
    "            \"Everything was great, only the delivery took a long time\",\n",
    "            \"I'm not happy with the service, but the dress is great.\"\n",
    "           ]\n",
    "\n",
    "tokenized_comments = vectorizer.transform(comments)\n",
    "clf.predict(tokenized_comments.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8df6c9f-2d52-46fd-8075-e2d0d8db0c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The TF-IDF will apply\n",
    "# A Heading and a Stars variable created.\n",
    "# Divided into training set and test set.\n",
    "# 20% is used for the test sets and the parameter is set to 30.\n",
    "\n",
    "X_tfidf, y_tfidf = df['Heading'], df['Stars']\n",
    "X_train_tfidf,X_test_tfidf,y_train_tfidf,y_test_tfidf = train_test_split(X_tfidf, y_tfidf, test_size=0.2, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8f1c61-a9ed-43c3-833d-bccb646e4147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset is divided into training and test data.\n",
    "# There will create a vectorizer\n",
    "# And update from the X_train_tfidf and X_test_tfidf values\n",
    "\n",
    "vec_tfidf = TfidfVectorizer()\n",
    "\n",
    "X_train_tfidf = vec_tfidf.fit_transform(X_train_tfidf)\n",
    "X_test_tfidf = vec_tfidf.transform(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb62afe-9f19-4821-a679-0f26a5629a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There will apply a clf_tfidf classifier witch using the GradientBoostingClassifier\n",
    "clf_tfidf = GradientBoostingClassifier(\n",
    "            n_estimators = 100,\n",
    "            learning_rate = 1.0,\n",
    "            max_depth = 1,\n",
    "            random_state = 0\n",
    ")\n",
    "\n",
    "clf_tfidf.fit(X_train_tfidf,y_train_tfidf)\n",
    "\n",
    "y_pred_tfidf = clf_tfidf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05271c02-98d6-42d5-b96a-443bd898dc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation from classification report.\n",
    "# And the confution matrix.\n",
    "print( classification_report(y_test_tfidf, y_pred_tfidf) )\n",
    "conf_matrix_tfidf = pd.crosstab(y_test_tfidf, y_pred_tfidf, rownames=['Actual class'], colnames=['Predicted class'])\n",
    "conf_matrix_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5df0f1-fc1a-40f4-87bd-10f32b96f938",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "token_com_tfidf = vec_tfidf.transform(comments)\n",
    "clf_tfidf.predict(token_com_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfe9927-6323-49b0-8b07-eb2fbeedc80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n')\n",
    "print(r\"\"\"The TF-IDF has not improved much, but on the other hand it has changed more between 1 star and 5 stars, \n",
    "but it is not clearly better or worse, in one place it has gone down and in the other place it has gone up.\n",
    "\n",
    "The CountVectoriser method is better suited to our model.\"\"\")\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d651251d-c547-4399-bfb0-f9b10315e9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the stemming method, words are placed in their word stem.\n",
    "# Checking duplicates.\n",
    "# Creat the stemmer and define the stemming function\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "def stemming(words) :\n",
    "    output = []\n",
    "    for string in words :\n",
    "        root = stemmer.stem(string)\n",
    "        if (root not in output) : output.append(root)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdc5211-2787-41ee-aeeb-b982408cc809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the explanatory variable from the variable to be predicte\n",
    "# To perform the stemming, the sentences must be broken down into word sequences.\n",
    "X_stem, y_stem = df.Heading, df.Stars\n",
    "X_stem = X_stem.str.split()\n",
    "for i in range (0, len(X_stem)):\n",
    "    X_stem[i] = stemming(X_stem[i])\n",
    "    X_stem[i] = ' '.join(X_stem[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164597b4-7cd0-4560-8f43-79cc44fad2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset is divided into training and test data.\n",
    "# There will create a vectorizer\n",
    "# And update from the X_train_tfidf and X_test_tfidf values\n",
    "\n",
    "X_train_stem,X_test_stem,y_train_stem,y_test_stem = train_test_split( X_stem, y_stem, test_size=0.2, random_state=30)\n",
    "\n",
    "vec_stem = TfidfVectorizer()\n",
    "\n",
    "X_train_stem = vec_stem.fit_transform(X_train_stem)\n",
    "X_test_stem = vec_stem.transform(X_test_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64568ba-b432-49ef-9939-add140972636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The clf_stem classifier has been created and train the model\n",
    "# The prediction from calculation\n",
    "\n",
    "clf_stem = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_train_stem, y_train_stem)\n",
    "y_pred_stem = clf_stem.predict(X_test_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166c20fd-d147-41c4-a7b9-491720c411bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation from classification report.\n",
    "# And the confution matrix.\n",
    "\n",
    "print(classification_report(y_test_stem, y_pred_stem))\n",
    "conf_matrix_stem = pd.crosstab(y_test_stem, y_pred_stem, rownames=['Actual class'], colnames=['Predicted class'])\n",
    "conf_matrix_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e37ce9-4ed2-4140-bf8d-977dc7a5d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a4b58b-3997-4a07-9b30-9a5153ed0f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization is a technique that is more advanced than stemming \n",
    "# and should achieve better results with this pre-processing.\n",
    "# Initialize a lemmatizer\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatization(words) :\n",
    "    output = []\n",
    "    for string in words :\n",
    "        lemma = wordnet_lemmatizer.lemmatize(string)\n",
    "        if (lemma not in output) : output.append(lemma)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2303d6-b6b4-45ee-8981-4ce6007a8e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separates the explanatory variables from the predictive variables.\n",
    "# To perform lemmatisation, you separate the phrases and put them back together again.\n",
    "\n",
    "X_lem, y_lem = df.Heading, df.Stars\n",
    "\n",
    "X_lem = X_lem.str.split()\n",
    "\n",
    "for i in range (0, len(X_lem)):\n",
    "    X_lem[i] = lemmatization(X_lem[i])\n",
    "    X_lem[i] = ' '.join(X_lem[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c208ea84-e45f-49f8-bfcb-bff38414b994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate the dataset in training set and test set.\n",
    "# Update X_train_Lem and X_test_lem values\n",
    "\n",
    "X_train_lem, X_test_lem, y_train_lem, y_test_lem = train_test_split(X_lem, y_lem, test_size=0.2, random_state = 30)\n",
    "\n",
    "vec_lem = TfidfVectorizer()\n",
    "X_train_lem = vec_lem.fit_transform(X_train_lem)\n",
    "X_test_lem = vec_lem.transform(X_test_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a5e27a-b689-40ce-985d-6228a29cac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a clf_lem classifier and train the model on the training set\n",
    "# Prediction calculation \n",
    "\n",
    "clf_lem = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_train_lem, y_train_lem)\n",
    "y_pred_lem = clf_lem.predict(X_test_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f08ff3-541f-489b-a964-aa66092663a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation from classification report.\n",
    "# And the confution matrix.\n",
    "\n",
    "print( classification_report(y_test_lem, y_pred_lem))\n",
    "conf_matrix_lem = pd.crosstab(y_test_lem, y_pred_lem, rownames=['Actual class'], colnames=['Predicted class'])\n",
    "conf_matrix_lem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db643f4-0ec4-4a3a-a4a5-d93b9682a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\")\n",
    "print(r\"\"\"Improvements are now being made with Stemming and Lemmatisation, \n",
    "on the assumption that this will improve the results.\"\"\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747ec475-d1db-4212-b97d-f33206547f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the stemming method, words are placed in their word stem.\n",
    "# Checking duplicates.\n",
    "# Creat the stemmer and define the stemming function\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "def stemming(words) :\n",
    "    output = []\n",
    "    for string in words :\n",
    "        root = stemmer.stem(string)\n",
    "        if (root not in output) : output.append(root)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1d7542-66a5-4ef4-8807-21ae7769ebb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the explanatory variable from the variable to be predicte\n",
    "# To perform the stemming, the sentences must be broken down into word sequences.\n",
    "X_stem, y_stem = df.Heading, df.Stars\n",
    "X_stem = X_stem.str.split()\n",
    "for i in range (0, len(X_stem)):\n",
    "    X_stem[i] = stemming(X_stem[i])\n",
    "    X_stem[i] = ' '.join(X_stem[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade6febb-7ad9-4c18-9af1-4927eb2ecb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset is divided into training and test data.\n",
    "# There will create a vectorizer\n",
    "# And update from the X_train_tfidf and X_test_tfidf values\n",
    "\n",
    "X_train_stem,X_test_stem,y_train_stem,y_test_stem = train_test_split( X_stem, y_stem, test_size=0.2, random_state=30)\n",
    "\n",
    "vec_stem = TfidfVectorizer()\n",
    "\n",
    "X_train_stem = vec_stem.fit_transform(X_train_stem)\n",
    "X_test_stem = vec_stem.transform(X_test_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6163b72f-9465-4052-b4f5-706de7d2e378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The clf_stem classifier has been created and train the model\n",
    "# The prediction from calculation\n",
    "\n",
    "clf_stem = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_train_stem, y_train_stem)\n",
    "y_pred_stem = clf_stem.predict(X_test_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bdbe64-6f75-4916-9f54-f7ce58caf9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation from classification report.\n",
    "# And the confution matrix.\n",
    "\n",
    "print(classification_report(y_test_stem, y_pred_stem))\n",
    "conf_matrix_stem = pd.crosstab(y_test_stem, y_pred_stem, rownames=['Actual class'], colnames=['Predicted class'])\n",
    "conf_matrix_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cfb62e-5cf6-4760-bd63-f611813e3baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\")\n",
    "print(r\"\"\"In the precision column, almost all values have risen well except for weighted avg, \n",
    "where the values have fallen slightly. \n",
    "More false positive scores were avoided. \n",
    "\n",
    "In the confution matrix, the TrueNegative and FalseNegative values have gone up and \n",
    "the FalsePositive and TruePsoitive values have gone down slightly. \n",
    "This means that more true and false negative evaluations were recognised \n",
    "and fewer false and true positive evaluations were recognised.\"\"\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c127b9c6-74d3-4a63-b86f-d89e7ad41f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization is a technique that is more advanced than stemming \n",
    "# and should achieve better results with this pre-processing.\n",
    "# Initialize a lemmatizer\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatization(words) :\n",
    "    output = []\n",
    "    for string in words :\n",
    "        lemma = wordnet_lemmatizer.lemmatize(string)\n",
    "        if (lemma not in output) : output.append(lemma)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061c5e8c-e0e4-4667-b7f7-91f327ddb70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separates the explanatory variables from the predictive variables.\n",
    "# To perform lemmatisation, you separate the phrases and put them back together again.\n",
    "\n",
    "X_lem, y_lem = df.Heading, df.Stars\n",
    "\n",
    "X_lem = X_lem.str.split()\n",
    "\n",
    "for i in range (0, len(X_lem)):\n",
    "    X_lem[i] = lemmatization(X_lem[i])\n",
    "    X_lem[i] = ' '.join(X_lem[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f6d22d-3c50-454d-8e3f-24c060087333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate the dataset in training set and test set.\n",
    "# Update X_train_Lem and X_test_lem values\n",
    "\n",
    "X_train_lem, X_test_lem, y_train_lem, y_test_lem = train_test_split(X_lem, y_lem, test_size=0.2, random_state = 30)\n",
    "\n",
    "vec_lem = TfidfVectorizer()\n",
    "X_train_lem = vec_lem.fit_transform(X_train_lem)\n",
    "X_test_lem = vec_lem.transform(X_test_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ed47d2-2eb3-41b5-a09f-08181c8a66f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a clf_lem classifier and train the model on the training set\n",
    "# Prediction calculation \n",
    "\n",
    "clf_lem = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X_train_lem, y_train_lem)\n",
    "y_pred_lem = clf_lem.predict(X_test_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85b6150-2932-4226-8076-81a7e7b50f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation from classification report.\n",
    "# And the confution matrix.\n",
    "\n",
    "print( classification_report(y_test_lem, y_pred_lem))\n",
    "conf_matrix_lem = pd.crosstab(y_test_lem, y_pred_lem, rownames=['Actual class'], colnames=['Predicted class'])\n",
    "conf_matrix_lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f43834c-a689-4ce8-b2b4-092ccd3068f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\")\n",
    "print(r\"\"\"\n",
    "Here, too, little has changed and, above all, there are very few improvements, \n",
    "rather deteriorations, so I tend not to use this method for our data. \n",
    "The CountVectoriser method and the stemming method for improvements.\n",
    "\n",
    "However, the improvement can be omitted here, because the macro avg and \n",
    "weighted avg in the precision column deteriorate and in other places there \n",
    "is only a very tiny increase in the values. \n",
    "\n",
    "It is therefore not worth applying tuning to our data. Cleaning up stop words \n",
    "and unnecessary elements makes the most sense and gives the best results.\"\"\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9888737-7c5b-4e12-afba-4eda5730b42d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0d8130-825f-41ad-9f59-31c621af4e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf202648-d182-4856-8ed4-418ff77840ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c844209e-90ee-408f-9de8-b14aeb48cf4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5e1e8a-9179-4bb4-885b-9490d1e66d96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afd0d0b-b13c-4d7f-93a0-0c0e3e93f3c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b77565-8b05-41d3-9574-cbe4b44a70e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
